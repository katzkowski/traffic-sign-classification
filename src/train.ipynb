{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import math\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import TrafficSignDataset\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib.patches import Rectangle\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from networks import TrafficSignsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import get_transforms\n",
    "# transform = None\n",
    "transform = get_transforms(img_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrafficSignDataset(\"..\\data\\Train.csv\", \"..\\data\", transform=transform)\n",
    "\n",
    "# randomly split into train and validation, regardless of frame sequences\n",
    "train, val = random_split(dataset, [math.floor(len(dataset) * 0.9), math.ceil(len(dataset) * 0.1)], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(len(train), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols, rows = 5, 6\n",
    "idx = 0 # index of frame sequence\n",
    "\n",
    "figure = plt.figure(figsize=(20, 24))\n",
    "\n",
    "for i in range(idx * 30, idx * 30 + 30):\n",
    "    img, target = train[i]\n",
    "\n",
    "    figure.add_subplot(cols, rows, i - (idx * 30) + 1)\n",
    "    plt.imshow(img.byte().permute(1,2,0))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    bbox = target[\"bbox\"]\n",
    "    x = bbox[2]\n",
    "    y = bbox[3]\n",
    "    box_width = bbox[4] - x\n",
    "    box_height = bbox[5] - y\n",
    "\n",
    "    rect = Rectangle((x,y), box_width, box_height, linewidth=1, edgecolor='r',facecolor='none')\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,1, figsize=(15,15))\n",
    "\n",
    "# training data\n",
    "train_labels, train_counts = np.unique((train.dataset.targets[\"ClassId\"])[train.indices], return_counts=True)\n",
    "ax[0].bar(train_labels, train_counts / len(train) * 100)\n",
    "\n",
    "# validation data\n",
    "val_labels, val_counts = np.unique((val.dataset.targets[\"ClassId\"])[val.indices], return_counts=True)\n",
    "ax[1].bar(val_labels, val_counts, color=\"orange\")\n",
    "\n",
    "\n",
    "# val - train\n",
    "diff = val_counts / len(val) - train_counts / len(train)\n",
    "\n",
    "ax[2].bar(train_labels, diff * 100, color=np.where(diff >= 0, \"orange\",\"C0\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataloaders\n",
    "train_dataloader = DataLoader(train, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val, batch_size=32, shuffle=False)\n",
    "# TODO: test_dataloader\n",
    "\n",
    "# to test training setup for errors\n",
    "sample_subset = Subset(dataset, np.arange(640))\n",
    "sample_dataloader =  DataLoader(sample_subset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"lr\": 1e-3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init model\n",
    "model = TrafficSignsClassifier(hparams, input_size=32, num_classes=len(train_labels))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=hparams[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tensorboard log\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "writer = SummaryWriter(f\"../runs/1_layer_linear_clf_{timestamp}\")\n",
    "\n",
    "correct = 0.0\n",
    "total = 0\n",
    "max_epochs = 20\n",
    "validate_every = 1\n",
    "\n",
    "min_val_loss = None\n",
    "patience = 0\n",
    "stopping_threshold = 5\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(tqdm(train_dataloader)):\n",
    "        # move data to device\n",
    "        x, y = data\n",
    "        x = x.to(device)\n",
    "        y = y[\"label\"].to(device)\n",
    "\n",
    "        # zero param gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimizer\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # calc stats\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(logits, 1)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "        \n",
    "    # print stats to console\n",
    "    running_loss /= len(train_dataloader)\n",
    "    correct /= total\n",
    "    print(\"[Epoch %d/%d] loss: %.3f acc: %.2f %%\" % (epoch+1, max_epochs, running_loss, 100*correct))\n",
    "\n",
    "    # log to tensorboard\n",
    "    writer.add_scalar('Training loss', running_loss, epoch * len(train_dataloader) + i)\n",
    "    writer.add_scalar('Training acc', correct, epoch * len(train_dataloader))\n",
    "\n",
    "    # reset stats after epoch\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0\n",
    "\n",
    "    # validation loop\n",
    "    if epoch % validate_every == (validate_every - 1):\n",
    "\n",
    "        val_running_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(val_dataloader):\n",
    "                x, y = data\n",
    "                x, y = x.to(device), y[\"label\"].to(device)\n",
    "                \n",
    "                logits = model(x)\n",
    "                val_loss = criterion(logits, y)\n",
    "                val_running_loss += val_loss.item()\n",
    "\n",
    "                _, preds = torch.max(logits, 1)\n",
    "                val_acc += preds.eq(y).sum().item()\n",
    "                val_total += y.size(0)\n",
    "\n",
    "\n",
    "        val_running_loss /= len(val_dataloader)\n",
    "        val_acc /= val_total\n",
    "        print(\"Validation loss: %.3f acc: %.2f\" % (val_running_loss, val_acc * 100))\n",
    "\n",
    "        # log to tensorboard\n",
    "        writer.add_scalar('Validation loss', val_running_loss, epoch * len(train_dataloader) + i)\n",
    "        writer.add_scalar('Validation acc', val_acc, epoch * len(train_dataloader))\n",
    "    \n",
    "        # save best model and early stopping\n",
    "        if min_val_loss is None or val_running_loss < min_val_loss:\n",
    "            patience = 0\n",
    "            min_val_loss = val_running_loss\n",
    "            best_acc = val_acc\n",
    "\n",
    "            # save params\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "        elif patience >= stopping_threshold:\n",
    "            print(\"Early stopping, best model at epoch \", epoch - stopping_threshold)\n",
    "            break\n",
    "        else:\n",
    "            patience += 1\n",
    "            continue\n",
    "\n",
    "# load best weights\n",
    "model.load_state_dict(best_model_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_labels)\n",
    "\n",
    "confusion_matrix = torch.zeros(num_classes, num_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(val_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y[\"label\"].to(device)\n",
    "        outputs = model(x)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(y.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t, p] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "rows_sum = confusion_matrix.sum(axis=1)\n",
    "\n",
    "norm_confusion_matrix = confusion_matrix / rows_sum[:, np.newaxis]\n",
    "\n",
    "sns.set(rc={'figure.figsize':(24,20)})\n",
    "ax = sns.heatmap(norm_confusion_matrix, annot=True, cmap='Blues', fmt='.1f')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28ba2f32f3a695c978abacd56b304aa4de162295fc3a67cb69c1cbb34fdbab11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
